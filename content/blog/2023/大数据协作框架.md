---
title: "大数据协作框架"
date: 2018-07-13 09:14:06
draft: false
---
学习了hadoop和hive之后，就可以对例如日志类型的海量数据进行分析处理，数据存储在hdfs上，用mapreduce或者hive来进行处理，但是你会发现还有一些问题

第一个问题:

数据来源?海量数据如何存储到hdfs上?

现实数据来源有两个方面:

/*RDBMS(oracle mysql DB2.......) ---> sqoop （SQL to HADOOP）

/*文件(apache nginx日志数据) ----->Flume （实时抽取数据）

第二个问题:

对数据的分析任务Job，至少都是上百上千，如何调度任务? （什么时候执行，多久执行一次，执行频率）

某一些业务的分析，需要许多Job任务共同完成，它们之间有着相互依赖关系，工作流如何调度?

-----------> Oozie

第三个问题:

通过上边的你会发现hadoop的生态框架有这么多，如果每一个框架都打开一个WEB UI页面来进行监控，会很麻烦，这时候就需要一个统一的WEB UI来进行监控

------------> Hue

以上的

数据转换工具sqoop

文件收集框架Flume

任务调度框架Oozie

大数据WEB工具Hue 统称为大数据协作框架，当然这些只是现在作用于现实中最广泛的