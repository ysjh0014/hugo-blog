---
title: "如何入门大数据"
date: 2018-11-06 19:51:03
draft: false
---
作为一名大数据的初学者，你可能会有很多疑惑

如何入门？要学什么？要会什么？学到什么程度能找工作？能赚多少钱？这篇文章，写给：刚刚入门大数据的同学

现在，大数据方向的大致分为以下几类：

1.大数据工程师（平台开发）

2.大数据运维（平台维护）

3.数据分析师（算法、机器学习等）

4.大数据科学家

因为我的方向就是大数据工程师，所以在这里就介绍一下

1.技能掌握

2.如何入门

3.学习渠道

**一.需要掌握哪些技能：**

想要成为一名大数据工程师，需要掌握一些什么技能

我们可以随便找一家求职网站或者App，搜索职位：大数据工程师

以下面这张招聘为例：

![](http://www.louisvv.com/wp-content/uploads/2017/11/20171117161419_55390.jpg)

如上图，一共有5条，后两条和经验要求先忽略不看

第一条：要掌握1~2门的编程语言，熟练使用Linux，并可以进行脚本的编写

第二条：对大数据的技术框架要求，需要熟悉Hadoop，Hbase，Hive，Spark，Storm等技术

第三条：要熟悉一些主流的消息中间件、内存数据库

第四条：要熟悉一些主流的数据工具、检索技术

我们总结一下：

1.要掌握一种或多种语言，Java语言（入门需掌握JavaSe），Scala语言（使用Spark会用到，入门掌握基本使用）

2.熟练使用Linux操作系统，基本shell的使用，ssh，ip，hosts，环境变量等配置

3.熟悉主流大数据框架Hadoop，Spark

4.熟悉Hadoop周边框架 Zookeeper，Hbase，Hive，Sqoop，Flume，Kafka，Storm等

5.sql的基本使用，基本增删改查，权限等

6.了解Redis、Memcache、ES、Solr等技术

**二.如何入门：**

根据上边总结的6点该如何入门呢？

**第一阶段：**

1.先学习一门编程语言，JavaSe

2.学习Linux基本操作，查看，创建文件/目录，删除，目录切换，解压文件等

**第二阶段：**

3.掌握Hadoop各种模式下的安装，学习HDFS设计原理和读写原理，熟练使用HDFS，学习Hadoop的Mapreduce的核心思想，尤其是shuffle！

4.熟悉周边框架 Zookeeper，Hbase，Hive，Sqoop，Flume的搭建和使用

要知道框架的基本概念，如何搭建，如何使用

其中Hbase，Hive要重点学习，安装，使用，熟悉！

5.sql基础入门，增删改查语句使用

**第三阶段：**

6.基于前五条的基础，可以开始了解：

(1)消息队列kafka的基本概念，使用

(2)实时处理系统：storm和spark Streaming

(3)Spark平台

(4)ES、Solr等

**三.学习渠道：**

无非就是自学和培训

自学的同学可以关注我的博客文章或者给我留言，提供给你学习大数据的视频

最后当觉得自己学的程度差不多了，可以去参加几次面试，对自身的实力进行一下检验

面试受挫了，也不要气馁，总结经验，继续努力，加油！